{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3e1d58d",
   "metadata": {},
   "source": [
    "# Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660b2f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.fft import fft, rfft, irfft\n",
    "\n",
    "from yaml import safe_load"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ea7448",
   "metadata": {},
   "source": [
    "**Load files**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc713a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_instance_file(filepath, filename, columns_names):\n",
    "    \n",
    "    full_filepath = filepath.format(filename)\n",
    "    df = pd.read_csv('../{}'.format(full_filepath), names=columns_names)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def load_instance_set_files(instance_catalog, labels):\n",
    "    \n",
    "    dfs = []\n",
    "    \n",
    "    filepath = instance_catalog['filepath']\n",
    "    columns_names = instance_catalog['columns']\n",
    "    \n",
    "    initial_value = int(instance_catalog['name_value_range'][0])\n",
    "    final_value = int(instance_catalog['name_value_range'][1])     \n",
    "        \n",
    "    for i in range(initial_value, final_value + 1):\n",
    "        \n",
    "        df_ = load_instance_file(filepath, i, columns_names)\n",
    "        df_['label'] = labels.iloc[i-1]['label']\n",
    "        df_['sample'] = i\n",
    "        df_['sample_index'] = df_.index.tolist()\n",
    "        df_ = df_.set_index(['sample', 'sample_index'])\n",
    "        dfs.append(df_)\n",
    "        \n",
    "    df = pd.concat(dfs, axis=0, ignore_index=False)\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff939618",
   "metadata": {},
   "source": [
    "**Calculate fft**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0d2ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_fft(df, col, samples, N=70000):\n",
    "    \n",
    "    df_ = df.copy()\n",
    "    \n",
    "    mat_X = np.zeros(shape=(int(N/2), len(samples)))\n",
    "    \n",
    "    for i, sample in enumerate(samples):\n",
    "        \n",
    "        x = df_.loc[sample][col].values\n",
    "        mat_X[:, i] = np.abs(fft(x) * 2 / N)[:int(N/2)]\n",
    "        \n",
    "    return mat_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dbf052d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df_esp_freq(mat_X, samples, N_max, col, axis_concat=0, data_freq = None):\n",
    "    \n",
    "    indexes = ['X_{}'.format(f) for f in range(N_max)]\n",
    "    multidx_cols = [*zip([col]*len(indexes), indexes)]\n",
    "    indexes_ = pd.MultiIndex.from_tuples(multidx_cols)\n",
    "    \n",
    "    data_freq_ = pd.DataFrame(data=mat_X[:N_max], \n",
    "                            columns=samples, \n",
    "                            index=indexes_)\n",
    "    \n",
    "    data_freq_ = data_freq_.T\n",
    "    \n",
    "    if data_freq is None:\n",
    "        data_freq = data_freq_ \n",
    "        \n",
    "    else:\n",
    "        data_freq = pd.concat([data_freq, data_freq_], axis=axis_concat, ignore_index=False)\n",
    "    \n",
    "    return data_freq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d85cafe2",
   "metadata": {},
   "source": [
    "**Get peaks positions and values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f5d4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_peaks_positions_values(data_f, channel, labels_considered=['Before', 'After'], add_label=True):\n",
    "    \n",
    "    list_peaks_idx = []\n",
    "    set_unique_peaks_idx = []\n",
    "    list_peaks_values = []\n",
    "\n",
    "    # Getting peaks indices\n",
    "    for i, x in data_f.loc[data_f.label.isin(labels_considered)].drop(columns='label')[channel].iterrows():\n",
    "\n",
    "        peaks_idx, _ = signal.find_peaks(x, threshold=np.quantile(x, 0.15))\n",
    "        list_peaks_idx.append(peaks_idx)\n",
    "        list_peaks_values.append(x[peaks_idx].values)\n",
    "\n",
    "    # Getting unique values of indices\n",
    "    set_peaks_idx = set()\n",
    "    for peaks_idx in list_peaks_idx:\n",
    "        for idx in peaks_idx:\n",
    "            set_peaks_idx.add(idx)\n",
    "\n",
    "    # Selecting only the columns related to the peaks\n",
    "    data_freq_peaks = data_f.iloc[:, list(set_peaks_idx)]\n",
    "    \n",
    "    # Renaming the columns to adding the prefix \"ch{}_\"\n",
    "    data_freq_peaks.columns = data_freq_peaks.columns.droplevel(level=0)\n",
    "    data_freq_peaks = data_freq_peaks.rename(columns = {col: '{}_{}'.format(channel, col) for col in data_freq_peaks.columns})\n",
    "    \n",
    "    if add_label:\n",
    "        data_freq_peaks = data_freq_peaks.join(data_f.label, on=data_freq_peaks.index)\n",
    "    \n",
    "    return data_freq_peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa15167",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_peaks_positions_values(data_f, channel, labels_considered=['Before', 'After'], add_label=True):\n",
    "    \n",
    "    list_peaks_idx = []\n",
    "    set_unique_peaks_idx = []\n",
    "    list_peaks_values = []\n",
    "\n",
    "    # Getting peaks indices\n",
    "    for i, x in data_f.loc[data_f.label.isin(labels_considered)].drop(columns='label')[channel].iterrows():\n",
    "\n",
    "        peaks_idx, _ = signal.find_peaks(x, threshold=np.quantile(x, 0.15))\n",
    "        list_peaks_idx.append(peaks_idx)\n",
    "        list_peaks_values.append(x[peaks_idx].values)\n",
    "\n",
    "    # Getting unique values of indices\n",
    "    set_peaks_idx = set()\n",
    "    for peaks_idx in list_peaks_idx:\n",
    "        for idx in peaks_idx:\n",
    "            set_peaks_idx.add(idx)\n",
    "\n",
    "    # Selecting only the columns related to the peaks\n",
    "    data_freq_peaks = data_f.iloc[:, list(set_peaks_idx)]\n",
    "    \n",
    "    # Renaming the columns to adding the prefix \"ch{}_\"\n",
    "    data_freq_peaks.columns = data_freq_peaks.columns.droplevel(level=0)\n",
    "    data_freq_peaks = data_freq_peaks.rename(columns = {col: '{}_{}'.format(channel, col) for col in data_freq_peaks.columns})\n",
    "    \n",
    "    if add_label:\n",
    "        data_freq_peaks = data_freq_peaks.join(data_f.label, on=data_freq_peaks.index)\n",
    "    \n",
    "    return data_freq_peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446a62f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_cols_names_channel(df, channel='ch1'):\n",
    "    return [col for col in df.columns if col.split('_', 1)[0] == channel]\n",
    "\n",
    "def select_cols_channel(df, channel='ch1'):\n",
    "    cols_names = select_cols_names_channel(df, channel=channel)\n",
    "    return df[cols_names]\n",
    "\n",
    "def get_peaks_pos(df, channel, n_max_positions=3):\n",
    "    \n",
    "    df_ = select_cols_channel(df, channel=channel)\n",
    "    N_samples = len(df_.columns)\n",
    "    \n",
    "    array_peaks_pos = np.zeros(shape=(len(df_), n_max_positions))\n",
    "\n",
    "    for i, row in df_.iterrows():\n",
    "        row_ = row.copy()\n",
    "        for pos in range(1, n_max_positions+1):\n",
    "            \n",
    "            idx_max = row_.argmax() \n",
    "            position = int(row_.index[idx_max].split('_')[-1])\n",
    "            row_ = row_.drop(index = row_.index[idx_max])\n",
    "\n",
    "            array_peaks_pos[i-1, pos-1] = position / N_samples\n",
    "\n",
    "    data_peak_pos = pd.DataFrame(data=array_peaks_pos, \n",
    "                                 columns = ['{}_freqmax_{}'.format(channel, i) for i in range(1, n_max_positions+1)], \n",
    "                                 index = df_.index)\n",
    "\n",
    "    return data_peak_pos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91ee3ff",
   "metadata": {},
   "source": [
    "**Calculate RMS of fundamental frequency and harmonics components, and RMS of \"noise\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8366da63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parabolic(f, x):\n",
    "\n",
    "    if int(x) != x:\n",
    "        raise ValueError('x must be an integer sample index')\n",
    "    else:\n",
    "        x = int(x)\n",
    "    xv = 1/2. * (f[x-1] - f[x+1]) / (f[x-1] - 2 * f[x] + f[x+1]) + x\n",
    "    yv = f[x] - 1/4. * (f[x-1] - f[x+1]) * (xv - x)\n",
    "    return (xv, yv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "526ba011",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_tdhn(df, col, samples, N=70000, beta_filter=38, n_harm=5, wind_fund_ratio=0.1, f_max=250):\n",
    "    \n",
    "    df_ = df.loc[samples][col].unstack().copy()\n",
    "    \n",
    "    mat_X = np.zeros(shape=(int(N/2 + 1), len(samples))) # Row: frequency, column: sample\n",
    "    mat_X_noise = mat_X.copy()\n",
    "    \n",
    "    f_fund = []\n",
    "    rms_total = []\n",
    "    rms_noise = []\n",
    "    \n",
    "    # Defining and window\n",
    "    window = signal.windows.kaiser(M=N, beta=beta_filter) \n",
    "    windowed = (df_.values * window).T  # Row: Time, column: Sample \n",
    "\n",
    "    for i, sample in enumerate(samples):\n",
    "        \n",
    "        x = windowed[:, i]\n",
    "        X = rfft(x)\n",
    "        mat_X[:, i] =  np.abs(X)\n",
    "        \n",
    "        fund_f_idx = np.argmax(np.abs(X[:f_max]))\n",
    "        true_f_idx = parabolic(np.log(np.abs(X)), fund_f_idx)[0]\n",
    "        f_fund.append(true_f_idx)\n",
    "        \n",
    "        rms_total.append(20*np.log10(np.sqrt(np.abs(X.T @ X))))\n",
    "        \n",
    "        # Setting fundamental and harmonic regions to zero\n",
    "        for nn in range(1, n_harm + 1):\n",
    "\n",
    "            lowermin = int(true_f_idx * nn * (1 - wind_fund_ratio))\n",
    "            uppermin = int(true_f_idx * nn * (1 + wind_fund_ratio))\n",
    "\n",
    "            X[lowermin : uppermin] = 0.0\n",
    "        \n",
    "        mat_X_noise[:, i] = np.abs(X)\n",
    "        \n",
    "        rms_noise.append(20*np.log10(np.sqrt(np.abs(X.T @ X))))\n",
    "        \n",
    "    return f_fund, rms_total, rms_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a0b30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tdhn_by_channel(df, channel='ch1', add_channel_prefix=True):\n",
    "    df_ = df.copy()\n",
    "    samples_before = df_.loc[data['label'] == 'Before'].index.get_level_values(level=0).unique().tolist()\n",
    "    f_fund_before, rms_total_before, rms_noise_before = calculate_tdhn(df_, channel, samples_before)\n",
    "\n",
    "    samples_after = df_.loc[data['label'] == 'After'].index.get_level_values(level=0).unique().tolist()\n",
    "    f_fund_after, rms_total_after, rms_noise_after = calculate_tdhn(df_, channel, samples_after)\n",
    "\n",
    "    # Creating a DF with the results\n",
    "    df_tdhn = pd.DataFrame(index=samples_before, \n",
    "                           data={'ffund': f_fund_before, \n",
    "                                 'rms_total' : rms_total_before,\n",
    "                                'rms_noise': rms_noise_before})\n",
    "\n",
    "    df_tdhn_ = pd.DataFrame(index=samples_after, \n",
    "                           data={'ffund': f_fund_after, \n",
    "                                'rms_total' : rms_total_after,\n",
    "                                'rms_noise': rms_noise_after})\n",
    "\n",
    "    df_tdhn = pd.concat([df_tdhn, df_tdhn_], axis=0, ignore_index=False)\n",
    "    df_tdhn['rms_ratio'] = df_tdhn['rms_noise'] / df_tdhn['rms_total']\n",
    "    \n",
    "    if add_channel_prefix:\n",
    "        rename_cols = {col : f\"{channel}_{col}\" for col in df_tdhn.columns}\n",
    "        df_tdhn = df_tdhn.rename(columns = rename_cols)\n",
    "\n",
    "    return df_tdhn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6595f959",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
